{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6115596e",
   "metadata": {},
   "source": [
    "# Importing Libraries:\n",
    "\n",
    "### pandas: used for data manipulation and analysis\n",
    "### os: used to interact with the operating system\n",
    "### numpy: used for numerical computing with arrays and matrices\n",
    "### unittest: used for writing and running unit tests\n",
    "### train_test_split: used to split the data into training and testing sets\n",
    "### mean_squared_error: used to calculate the mean squared error metric\n",
    "### joblib: used to calculate the mean squared error metric\n",
    "### xgb: Machine Learning Algorithm used for machine learning tasks\n",
    "### pickle: used for object serialization and deserialization\n",
    "### logging: used for emitting log messages from your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67910324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15199\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import unittest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a910eedc",
   "metadata": {},
   "source": [
    "# Converting all csv files into a dataframe\n",
    "\n",
    "### Loading ETF and stock datasets\n",
    "### Datasets avaialble at: https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset\n",
    "### Converting all csv files of ETF and stocks into a dataframe and merging that with symbols_valid_meta.csv to get security_name column and saving the dataframe in combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "402a7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing the CSV files\n",
    "folder_paths = ['etfs/','stocks/']\n",
    "updated_dfs = []\n",
    "\n",
    "# Looping through the folders of etfs and stocks\n",
    "for folder_path in folder_paths:\n",
    "    # Creating an empty list to store individual DataFrames\n",
    "    dfs = []\n",
    "    file_names = []\n",
    "\n",
    "    # Iterating over each file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Getting the full file path which includes the path and the filename\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Reading the CSV file into a DataFrame. Since each file has it's own csv file\n",
    "            df = pd.read_csv(file_path)\n",
    "            # getting the filename of each csv file and loading the same in a column called symbol\n",
    "            df['Symbol'] = filename.replace('.csv', '')\n",
    "            # Creating different dataframes and appending that to a list\n",
    "            dfs.append(df)\n",
    "            # Store the filename of all the files in a list\n",
    "            file_names.append(filename)\n",
    "\n",
    "    # Combine all DataFrames in the list into a single DataFrame\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "    # Read the CSV file which has the security name. Here the file_names is being used to get the security_names\n",
    "    comparison_file_path = 'symbols_valid_meta.csv'\n",
    "    comparison_df = pd.read_csv(comparison_file_path)\n",
    "\n",
    "    # Creating a new DataFrame with only the 'Symbol' and 'security_name' columns from the comparison DataFrame\n",
    "    comparison_subset = comparison_df[['Symbol', 'Security Name']]\n",
    "\n",
    "    # Merging the comparison DataFrame subset with the combined DataFrame based on the 'Symbol' column\n",
    "    df = pd.merge(df, comparison_subset, on='Symbol', how='left')\n",
    "    updated_dfs.append(df)\n",
    "\n",
    "\n",
    "etfs_df = updated_dfs[0]\n",
    "stocks_df = updated_dfs[1]\n",
    "\n",
    "\n",
    "combined_df = pd.concat([etfs_df, stocks_df], ignore_index=True)\n",
    "\n",
    "# Defining the columns so that they will be in the order as defined in the problem.\n",
    "columns = ['Symbol','Security Name', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "\n",
    "combined_df = combined_df[columns]\n",
    "combined_df.to_parquet(\"combined.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b14457fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>11.84</td>\n",
       "      <td>11.84</td>\n",
       "      <td>11.74</td>\n",
       "      <td>11.74</td>\n",
       "      <td>11.74</td>\n",
       "      <td>27300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>11.78</td>\n",
       "      <td>11.80</td>\n",
       "      <td>11.74</td>\n",
       "      <td>11.74</td>\n",
       "      <td>11.74</td>\n",
       "      <td>428400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>11.80</td>\n",
       "      <td>11.82</td>\n",
       "      <td>11.77</td>\n",
       "      <td>11.82</td>\n",
       "      <td>11.82</td>\n",
       "      <td>52400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>11.88</td>\n",
       "      <td>11.91</td>\n",
       "      <td>11.85</td>\n",
       "      <td>11.90</td>\n",
       "      <td>11.90</td>\n",
       "      <td>28700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAU</td>\n",
       "      <td>Perth Mint Physical Gold ETF</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>11.92</td>\n",
       "      <td>11.95</td>\n",
       "      <td>11.89</td>\n",
       "      <td>11.93</td>\n",
       "      <td>11.93</td>\n",
       "      <td>30600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28148363</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex, Inc. - Common Stock</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>10.23</td>\n",
       "      <td>11.43</td>\n",
       "      <td>10.23</td>\n",
       "      <td>11.10</td>\n",
       "      <td>11.10</td>\n",
       "      <td>189500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28148364</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex, Inc. - Common Stock</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.98</td>\n",
       "      <td>10.06</td>\n",
       "      <td>10.30</td>\n",
       "      <td>10.30</td>\n",
       "      <td>145000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28148365</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex, Inc. - Common Stock</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>10.16</td>\n",
       "      <td>11.06</td>\n",
       "      <td>10.16</td>\n",
       "      <td>10.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>162300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28148366</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex, Inc. - Common Stock</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>10.68</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.59</td>\n",
       "      <td>11.07</td>\n",
       "      <td>11.07</td>\n",
       "      <td>280400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28148367</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex, Inc. - Common Stock</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>11.16</td>\n",
       "      <td>11.16</td>\n",
       "      <td>10.51</td>\n",
       "      <td>10.92</td>\n",
       "      <td>10.92</td>\n",
       "      <td>315900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28148368 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Symbol                 Security Name        Date   Open   High  \\\n",
       "0          AAAU  Perth Mint Physical Gold ETF  2018-08-15  11.84  11.84   \n",
       "1          AAAU  Perth Mint Physical Gold ETF  2018-08-16  11.78  11.80   \n",
       "2          AAAU  Perth Mint Physical Gold ETF  2018-08-17  11.80  11.82   \n",
       "3          AAAU  Perth Mint Physical Gold ETF  2018-08-20  11.88  11.91   \n",
       "4          AAAU  Perth Mint Physical Gold ETF  2018-08-21  11.92  11.95   \n",
       "...         ...                           ...         ...    ...    ...   \n",
       "28148363   ZYXI    Zynex, Inc. - Common Stock  2020-03-26  10.23  11.43   \n",
       "28148364   ZYXI    Zynex, Inc. - Common Stock  2020-03-27  10.70  10.98   \n",
       "28148365   ZYXI    Zynex, Inc. - Common Stock  2020-03-30  10.16  11.06   \n",
       "28148366   ZYXI    Zynex, Inc. - Common Stock  2020-03-31  10.68  11.14   \n",
       "28148367   ZYXI    Zynex, Inc. - Common Stock  2020-04-01  11.16  11.16   \n",
       "\n",
       "            Low  Close  Adj Close    Volume  \n",
       "0         11.74  11.74      11.74   27300.0  \n",
       "1         11.74  11.74      11.74  428400.0  \n",
       "2         11.77  11.82      11.82   52400.0  \n",
       "3         11.85  11.90      11.90   28700.0  \n",
       "4         11.89  11.93      11.93   30600.0  \n",
       "...         ...    ...        ...       ...  \n",
       "28148363  10.23  11.10      11.10  189500.0  \n",
       "28148364  10.06  10.30      10.30  145000.0  \n",
       "28148365  10.16  10.80      10.80  162300.0  \n",
       "28148366  10.59  11.07      11.07  280400.0  \n",
       "28148367  10.51  10.92      10.92  315900.0  \n",
       "\n",
       "[28148368 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a41d7",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### Calculating the moving average of the trading volume (Volume) of 30 days per each stock and ETF, and retain it in a newly added column vol_moving_avg\n",
    "\n",
    "### Calculating the median of the Adj Close of 30 days per each stock and ETF, and retain it in a newly added column adj_close_rolling_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d22af1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the moving average of the trading volume (Volume) for each stock and ETF\n",
    "grouped_df = combined_df.groupby('Symbol')\n",
    "moving_avg = grouped_df['Volume'].rolling(window=30).mean()\n",
    "\n",
    "# Reset the index and drop the original index to align with the combined_df\n",
    "moving_avg = moving_avg.reset_index(level=0, drop=True)\n",
    "\n",
    "# Assign the calculated moving average values to the vol_moving_avg column in combined_df\n",
    "combined_df['vol_moving_avg'] = moving_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "368b7f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rolling median of the 'Adj Close' column for each stock and ETF\n",
    "grouped_df = combined_df.groupby('Symbol')\n",
    "rolling_median = grouped_df['Adj Close'].rolling(window=30).median()\n",
    "\n",
    "# Reset the index and drop the original index to align with the combined_df\n",
    "rolling_median = rolling_median.reset_index(level=0, drop=True)\n",
    "\n",
    "# Assign the calculated rolling median values to the adj_close_rolling_med column in combined_df\n",
    "combined_df['adj_close_rolling_med'] = rolling_median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85698347",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_parquet(\"final_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792e3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_parquet(\"final_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146e0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340c397b",
   "metadata": {},
   "source": [
    "# Unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59aec838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Unittest for median:\n",
    "\n",
    "\n",
    "class RollingMedianTestCase(unittest.TestCase):\n",
    "    \n",
    "    def setUp(self):\n",
    "        # Creating a sample DataFrame for testing purpose\n",
    "        data = {\n",
    "            'Symbol': ['AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "            'Adj Close': [10, 20, 30, 40, 50, 60]\n",
    "        }\n",
    "        self.df = pd.DataFrame(data)\n",
    "    \n",
    "    def test_rolling_median(self):\n",
    "        # Calculating the rolling median for each stock/ETF of the sample dataset\n",
    "        expected_result = [10.0, 15.0, 25.0, 35.0, 45.0, 55.0]\n",
    "        # Grouping the dataframe by \"symbol\" column\n",
    "        grouped_df = self.df.groupby('Symbol')\n",
    "        # Then calculating \n",
    "        rolling_median = self.df['Adj Close'].rolling(window=2, min_periods=1).median()\n",
    "        rolling_median = rolling_median.reset_index(level=0, drop=True)\n",
    "        self.df['adj_close_rolling_med'] = rolling_median\n",
    "        \n",
    "        # Compare the calculated rolling median with the expected result\n",
    "        result = self.df['adj_close_rolling_med'].tolist()\n",
    "        self.assertEqual(result, expected_result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f66af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65994aa6",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Trained GBDT: (Gradient Boost Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b879e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocessing the data\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "\n",
    "# Setting the Date column as index\n",
    "combined_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Dropping rows with missing values\n",
    "combined_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the data into features and target\n",
    "features = combined_df[['vol_moving_avg', 'adj_close_rolling_med']]\n",
    "target = combined_df['Volume']\n",
    "\n",
    "# Step 4: splitting the features and target into Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features.values, target.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Setting up the logging configuration\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Training the Machine Learning model\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Logging the training metrics\n",
    "logging.info('Training Metrics:')\n",
    "# Using model that trained above for prediction \n",
    "y_pred = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "logging.info(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Evaluating the model on the test_data\n",
    "logging.info('Evaluation Metrics:')\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "logging.info(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Saving the trained model in the pkl format\n",
    "model_filename = 'xgb_model.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654f311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35aeb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67159e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434bec22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb272cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c4ba57",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a57f185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([420898.4], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the model\n",
    "# Creating the dataframe with vol_moving_avg and adj_close_rolling_med as columns\n",
    "input_data = pd.DataFrame({'vol_moving_avg': [421296.666667], 'adj_close_rolling_med': [11.095]})\n",
    "# Getting the \n",
    "expected_features = input_data.columns.tolist()\n",
    "input_df = input_data[expected_features]\n",
    "input_array = input_df.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.predict((input_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b80971b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df72a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
